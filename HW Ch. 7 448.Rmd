---
title: "HW Ch. 7 448"
output:
  pdf_document: default
  html_document: default
---

#3
```{r}
x = -2:2
y = 1 + x + -2 * (x-1)^2 * I(x>1)
plot(x, y)
```


#6 
```{r}
#a)
install.packages("ISLR", repos = "https://cran.rstudio.com")
install.packages("boot", repos = "https://cran.rstudio.com")
set.seed(10)
library(ISLR)
library(boot)
all.deltas = rep(NA, 10)
for (i in 1:10) {
  glm.fit = glm(wage~poly(age, i), data=Wage)
  all.deltas[i] = cv.glm(Wage, glm.fit, K=10)$delta[2]
}
plot(1:10, all.deltas, xlab="Degree", ylab="CV error", type="l", pch=20, lwd=2, 
     ylim=c(1590, 1700))
min.point = min(all.deltas)
sd.points = sd(all.deltas)
abline(h=min.point + 0.2 * sd.points, col="red", lty="dashed")
abline(h=min.point - 0.2 * sd.points, col="red", lty="dashed")
legend("topright", "0.2-standard deviation lines", lty="dashed", col="red")

#predict wage using AGE 
fit.1 = lm(wage~poly(age, 1), data = Wage)
fit.2 = lm(wage~poly(age, 2), data = Wage)
fit.3 = lm(wage~poly(age, 3), data = Wage)
fit.4 = lm(wage~poly(age, 4), data = Wage)
fit.5 = lm(wage~poly(age, 5), data = Wage)
fit.6 = lm(wage~poly(age, 6), data = Wage)
fit.7 = lm(wage~poly(age, 7), data = Wage)
fit.8 = lm(wage~poly(age, 8), data = Wage)
fit.9 = lm(wage~poly(age, 9), data = Wage)
fit.10 = lm(wage~poly(age, 10), data = Wage)
anova(fit.1, fit.2, fit.3, fit.4, fit.5, fit.6, fit.7, fit.8, fit.9, fit.10)

plot(wage ~ age, data = Wage, col = "darkgrey")
agelim = range(Wage$age)
age.grid = seq(from = agelim[1], to = agelim[2])
lm.fit = lm(wage~poly(age, 3), data = Wage)
lm.pred = predict(lm.fit, data.frame(age = age.grid))
lines(age.grid, lm.pred, col="blue", lwd = 2)

#wage tends to increase as does age, once retirement stage hits, then salary 
##tends to decrease slightly

#b) 
all.cvs = rep(NA, 10)

for (i in 2:10) {
  Wage$age.cut = cut(Wage$age, i)
  lm.fit = glm(wage~age.cut, data = Wage)
  all.cvs[i] = cv.glm(Wage, lm.fit, K = 10)$delta[2]
}
plot(2:10, all.cvs[-1], xlab ="Number of cuts", ylab ="CV error", type ="l", 
     pch =20, lwd =2)
#test error minimum for k = 8 cuts after using cross validation 

#use k = 8

lm.fit = glm(wage ~ cut(age, 8), data = Wage)
agelim = range(Wage$age)
age.grid = seq(from = agelim[1], to = agelim[2])
lm.pred = predict(lm.fit, data.frame(age = age.grid))
plot(wage ~ age, data = Wage, col ="darkgrey")
lines(age.grid, lm.pred, col ="red", lwd =2)

#high spike of wage increase from mid 20's to early/beginning 30's 
#steady incline from 40's to mid 50's, and 60 onwards begins slight decrease. 
```

#9 
```{r}
install.packages("MASS", repos = "https://cran.rstudio.com")
set.seed(10)
library(MASS)
attach(Boston)

#a) 
lm.fit = lm(nox ~ poly(dis, 3), data = Boston)
summary(lm.fit)

#all are significant based from the summary predicting nox using dis

dislim = range(dis)
dis.grid = seq(from = dislim[1], to = dislim[2], by = 0.1)

lm.pred = predict(lm.fit, list(dis = dis.grid))
plot(nox ~ dis, data = Boston, col = "darkgrey")
lines(dis.grid, lm.pred, col = "red", lwd = 2)
#curve fits data fairly well 

#b) 
all.rss = rep(NA, 10)
for (i in 1:10) {
    lm.fit = lm(nox ~ poly(dis, i), data = Boston)
    all.rss[i] = sum(lm.fit$residuals^2)
}
all.rss
#RSS decreases given the degree poly 

#c)
library(boot)
all.deltas = rep(NA, 10)
for (i in 1:10) {
    glm.fit = glm(nox ~ poly(dis, i), data = Boston)
    all.deltas[i] = cv.glm(Boston, glm.fit, K = 10)$delta[2]
}
plot(1:10, all.deltas, xlab = "degree", ylab = "cv error", type = "l", pch = 20, 
    lwd = 2)
#use 3 or 4 for best poly degree given that it has the lowest CV error. 

#d)
install.packages("splines", repos = "https://cran.rstudio.com" )
library(splines)
sp.fit = lm(nox ~ bs(dis, df = 4, knots = c(4, 7, 11)), data = Boston)
summary(sp.fit)
#all terms are significant in the spline fit. 

sp.pred = predict(sp.fit, list(dis = dis.grid))
plot(nox ~ dis, data = Boston, col = "darkgrey")
lines(dis.grid, sp.pred, col = "red", lwd =2)
#plot fits well given the data for the most part. Except for once it reaches 
##its extreme values it seems to be doing its own thing.

#e) 

#df from 3 to 16 
all.cv = rep(NA, 16)
for (i in 3:16) {
    lm.fit = lm(nox ~ bs(dis, df = i), data = Boston)
    all.cv[i] = sum(lm.fit$residuals^2)
}
all.cv[-c(1, 2)]
#Train RSS decrease until it reaches df @ 14, then increase for df 15 and 16. 

#f)

#use a 10-fold cv for df values between 3 and 16 
all.cv = rep(NA, 16)
for (i in 3:16) {
    lm.fit = glm(nox ~ bs(dis, df = i), data = Boston)
    all.cv[i] = cv.glm(Boston, lm.fit, K = 10)$delta[2]
}
plot(3:16, all.cv[-c(1, 2)], lwd = 2, type = "l", xlab = "df", ylab ="cv error")

#plot is quite choppy. 
#pick 5 or 11 as the most optimal df given that they have the lowest cv error. 
```

